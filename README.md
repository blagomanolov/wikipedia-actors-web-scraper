# wikipedia-actors-web-scraper
Scraping Data – Extracts actor information from Wikipedia and stores it in multiple JSON files, each categorized by country. Data Cleaning – Processes and refines the scraped data to remove inconsistencies and errors. CSV Conversion – Saves the cleaned data into a structured CSV format for easier analysis and usage.
